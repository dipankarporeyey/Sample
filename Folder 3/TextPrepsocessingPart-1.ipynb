{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2a53f929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "text preprocessing is an important step in natural language processing it involves cleaning and transforming raw text data into a format suitable for analysis\n",
      "\n",
      "Cleaned Text:\n",
      "text preprocessing important step natural language processing involves cleaning transforming raw text data format suitable analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\UJ415AV\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Sample text\n",
    "text = \"Text preprocessing is an important step in natural language processing. It involves cleaning and transforming raw text data into a format suitable for analysis.\"\n",
    "\n",
    "# Convert text to lowercase\n",
    "text = text.lower()\n",
    "\n",
    "# Remove punctuation and special characters\n",
    "text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "# Tokenize the text (split it into words)\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "# Stemming (using Porter stemmer)\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
    "\n",
    "# Lemmatization (using WordNet lemmatizer)\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "\n",
    "# Join the preprocessed tokens back into a clean text\n",
    "clean_text = ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Print the cleaned text\n",
    "print(\"Original Text:\")\n",
    "print(text)\n",
    "print(\"\\nCleaned Text:\")\n",
    "print(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8f8c7cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "61325b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "86bd34b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "92bc55e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer,WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e3ea3436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text preprocessing is an important step in natural language processing. It involves cleaning and transforming raw text data into a format suitable for analysis.\n"
     ]
    }
   ],
   "source": [
    "text = \"Text preprocessing is an important step in natural language processing. It involves cleaning and transforming raw text data into a format suitable for analysis.\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a0313456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text preprocessing is an important step in natural language processing. it involves cleaning and transforming raw text data into a format suitable for analysis.\n"
     ]
    }
   ],
   "source": [
    "text = text.lower()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "11d6401c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text preprocessing is an important step in natural language processing it involves cleaning and transforming raw text data into a format suitable for analysis\n"
     ]
    }
   ],
   "source": [
    "text = re.sub(r\"[^a-zA-Z0-9\\s]\",\"\",text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "85e2aeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'preprocessing', 'is', 'an', 'important', 'step', 'in', 'natural', 'language', 'processing', 'it', 'involves', 'cleaning', 'and', 'transforming', 'raw', 'text', 'data', 'into', 'a', 'format', 'suitable', 'for', 'analysis']\n"
     ]
    }
   ],
   "source": [
    "token = word_tokenize(text)\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0ef5a818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'preprocessing', 'important', 'step', 'natural', 'language', 'processing', 'involves', 'cleaning', 'transforming', 'raw', 'text', 'data', 'format', 'suitable', 'analysis']\n"
     ]
    }
   ],
   "source": [
    "token = [i for i in token if i not in set(stopwords.words(\"english\"))]\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f39274ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'preprocess', 'import', 'step', 'natur', 'languag', 'process', 'involv', 'clean', 'transform', 'raw', 'text', 'data', 'format', 'suitabl', 'analysi']\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "ps_token = [ps.stem(i) for i in token]\n",
    "print(ps_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7d56667f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'preprocessing', 'important', 'step', 'natural', 'language', 'processing', 'involves', 'cleaning', 'transforming', 'raw', 'text', 'data', 'format', 'suitable', 'analysis']\n"
     ]
    }
   ],
   "source": [
    "lmm = WordNetLemmatizer()\n",
    "lmm_token = [lmm.lemmatize(i) for i in token]\n",
    "print(lmm_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dd1cebc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text preprocess import step natur languag process involv clean transform raw text data format suitabl analysi\n"
     ]
    }
   ],
   "source": [
    "ps_join = \" \".join(ps_token)\n",
    "print(ps_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "48c01536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text preprocessing important step natural language processing involves cleaning transforming raw text data format suitable analysis\n"
     ]
    }
   ],
   "source": [
    "lmm_join = \" \".join(lmm_token)\n",
    "print(lmm_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555f1890",
   "metadata": {},
   "source": [
    "In this code:\n",
    "\n",
    "1. We start with a sample text that we want to preprocess.\n",
    "\n",
    "2. We convert the text to lowercase to ensure consistency.\n",
    "\n",
    "3. We remove punctuation and special characters using regular expressions (re.sub).\n",
    "\n",
    "4. We tokenize the text into individual words using NLTK's word_tokenize function.\n",
    "\n",
    "5. We remove common stopwords (e.g., \"the,\" \"and,\" \"is\") using NLTK's list of English stop words.\n",
    "\n",
    "6. We perform stemming on the remaining words using the Porter stemmer to reduce them to their base form.\n",
    "\n",
    "7. We also demonstrate lemmatization using the WordNet lemmatizer, which reduces words to their base or dictionary form.\n",
    "\n",
    "Finally, we join the preprocessed tokens back together into a clean text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b949862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
