{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f2c9a874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "text preprocessing is an important step in natural language processing it involves cleaning and transforming raw text data into a format suitable for analysis\n",
      "\n",
      "Cleaned Text:\n",
      "text preprocessing important step natural language processing involves cleaning transforming raw text data format suitable analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\UJ415AV\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Sample text\n",
    "text = \"Text preprocessing is an important step in natural language processing. It involves cleaning and transforming raw text data into a format suitable for analysis.\"\n",
    "\n",
    "# Convert text to lowercase\n",
    "text = text.lower()\n",
    "\n",
    "# Remove punctuation and special characters\n",
    "text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "# Tokenize the text (split it into words)\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "# Stemming (using Porter stemmer)\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
    "\n",
    "# Lemmatization (using WordNet lemmatizer)\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "\n",
    "# Join the preprocessed tokens back into a clean text\n",
    "clean_text = ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Print the cleaned text\n",
    "print(\"Original Text:\")\n",
    "print(text)\n",
    "print(\"\\nCleaned Text:\")\n",
    "print(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f89c6c",
   "metadata": {},
   "source": [
    "# 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c8011a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5cdf5239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "06037371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ceb82095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer,WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3c5207bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text preprocessing is an important step in natural language processing. It involves cleaning and transforming raw text data into a format suitable for analysis.\n"
     ]
    }
   ],
   "source": [
    "text = \"Text preprocessing is an important step in natural language processing. It involves cleaning and transforming raw text data into a format suitable for analysis.\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c66f4b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text preprocessing is an important step in natural language processing. it involves cleaning and transforming raw text data into a format suitable for analysis.\n"
     ]
    }
   ],
   "source": [
    "text = text.lower()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3b7e0c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text preprocessing is an important step in natural language processing it involves cleaning and transforming raw text data into a format suitable for analysis\n"
     ]
    }
   ],
   "source": [
    "text = re.sub(r\"[^a-zA-Z0-9\\s]\",\"\",text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "001c36db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'preprocessing', 'is', 'an', 'important', 'step', 'in', 'natural', 'language', 'processing', 'it', 'involves', 'cleaning', 'and', 'transforming', 'raw', 'text', 'data', 'into', 'a', 'format', 'suitable', 'for', 'analysis']\n"
     ]
    }
   ],
   "source": [
    "token = word_tokenize(text)\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1f76b1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'preprocessing', 'important', 'step', 'natural', 'language', 'processing', 'involves', 'cleaning', 'transforming', 'raw', 'text', 'data', 'format', 'suitable', 'analysis']\n"
     ]
    }
   ],
   "source": [
    "token = [i for i in token if i not in set(stopwords.words(\"english\"))]\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "88e46e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'preprocess', 'import', 'step', 'natur', 'languag', 'process', 'involv', 'clean', 'transform', 'raw', 'text', 'data', 'format', 'suitabl', 'analysi']\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "ps_token = [ps.stem(i) for i in token]\n",
    "print(ps_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a91c31f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'preprocessing', 'important', 'step', 'natural', 'language', 'processing', 'involves', 'cleaning', 'transforming', 'raw', 'text', 'data', 'format', 'suitable', 'analysis']\n"
     ]
    }
   ],
   "source": [
    "lmm = WordNetLemmatizer()\n",
    "lmm_token = [lmm.lemmatize(i) for i in token]\n",
    "print(lmm_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c1a51e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text preprocess import step natur languag process involv clean transform raw text data format suitabl analysi\n"
     ]
    }
   ],
   "source": [
    "ps_join = \" \".join(ps_token)\n",
    "print(ps_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4b966e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text preprocessing important step natural language processing involves cleaning transforming raw text data format suitable analysis\n"
     ]
    }
   ],
   "source": [
    "lmm_join = \" \".join(lmm_token)\n",
    "print(lmm_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2912e2",
   "metadata": {},
   "source": [
    "In this code:\n",
    "\n",
    "1. We start with a sample text that we want to preprocess.\n",
    "\n",
    "2. We convert the text to lowercase to ensure consistency.\n",
    "\n",
    "3. We remove punctuation and special characters using regular expressions (re.sub).\n",
    "\n",
    "4. We tokenize the text into individual words using NLTK's word_tokenize function.\n",
    "\n",
    "5. We remove common stopwords (e.g., \"the,\" \"and,\" \"is\") using NLTK's list of English stop words.\n",
    "\n",
    "6. We perform stemming on the remaining words using the Porter stemmer to reduce them to their base form.\n",
    "\n",
    "7. We also demonstrate lemmatization using the WordNet lemmatizer, which reduces words to their base or dictionary form.\n",
    "\n",
    "Finally, we join the preprocessed tokens back together into a clean text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ba5a34",
   "metadata": {},
   "source": [
    "# 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d2fb568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ph = \"In a world full of challenges, we often encounter 900 unexpected twists and turns in our journey. Life's path is not always smooth, and it's essential to navigate through the highs and lows with resilience and determination! Embracing each obstacle as an opportunity for growth and learning is the key to achieving success. So, don't be afraid to take risks, dream big, and make your mark on this exciting adventure called life.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "34bae2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a world full of challenges, we often encounter 900 unexpected twists and turns in our journey. Life's path is not always smooth, and it's essential to navigate through the highs and lows with resilience and determination! Embracing each obstacle as an opportunity for growth and learning is the key to achieving success. So, don't be afraid to take risks, dream big, and make your mark on this exciting adventure called life.\n"
     ]
    }
   ],
   "source": [
    "print(ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7000fdaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\",.','!.,',,.\""
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ph_1 = re.sub(r\"[a-zA-Z0-9\\s]\",\"\",ph)\n",
    "ph_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5d77c6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I         900        L                    E                S                  '"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ph_2 = re.sub(r\"[^A-Z0-9\\s]\",\"\",ph)\n",
    "ph_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4065bd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'         900                                                              '"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ph_3 = re.sub(r\"[^0-9\\s]\",\"\",ph)\n",
    "ph_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "64d908ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Inaworldfullofchallengesweoftenencounter900unexpectedtwistsandturnsinourjourneyLifespathisnotalwayssmoothanditsessentialtonavigatethroughthehighsandlowswithresilienceanddeterminationEmbracingeachobstacleasanopportunityforgrowthandlearningisthekeytoachievingsuccessSodontbeafraidtotakerisksdreambigandmakeyourmarkonthisexcitingadventurecalledlife'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ph_4 = re.sub(r\"[^a-zA-Z0-9]\",\"\",ph)\n",
    "ph_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b1a44a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n a world full of challenges we often encounter 900 unexpected twists and turns in our journey ifes path is not always smooth and its essential to navigate through the highs and lows with resilience and determination mbracing each obstacle as an opportunity for growth and learning is the key to achieving success o dont be afraid to take risks dream big and make your mark on this exciting adventure called life'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ph_5 = re.sub(r\"[^a-z0-9\\s]\",\"\",ph)\n",
    "ph_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4bea4fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"in a world full of challenges, we often encounter 900 unexpected twists and turns in our journey. life's path is not always smooth, and it's essential to navigate through the highs and lows with resilience and determination! embracing each obstacle as an opportunity for growth and learning is the key to achieving success. so, don't be afraid to take risks, dream big, and make your mark on this exciting adventure called life.\""
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ph = ph.lower()\n",
    "ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d9de1cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in',\n",
       " 'a',\n",
       " 'world',\n",
       " 'full',\n",
       " 'of',\n",
       " 'challenges',\n",
       " ',',\n",
       " 'we',\n",
       " 'often',\n",
       " 'encounter',\n",
       " '900',\n",
       " 'unexpected',\n",
       " 'twists',\n",
       " 'and',\n",
       " 'turns',\n",
       " 'in',\n",
       " 'our',\n",
       " 'journey',\n",
       " '.',\n",
       " 'life',\n",
       " \"'s\",\n",
       " 'path',\n",
       " 'is',\n",
       " 'not',\n",
       " 'always',\n",
       " 'smooth',\n",
       " ',',\n",
       " 'and',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'essential',\n",
       " 'to',\n",
       " 'navigate',\n",
       " 'through',\n",
       " 'the',\n",
       " 'highs',\n",
       " 'and',\n",
       " 'lows',\n",
       " 'with',\n",
       " 'resilience',\n",
       " 'and',\n",
       " 'determination',\n",
       " '!',\n",
       " 'embracing',\n",
       " 'each',\n",
       " 'obstacle',\n",
       " 'as',\n",
       " 'an',\n",
       " 'opportunity',\n",
       " 'for',\n",
       " 'growth',\n",
       " 'and',\n",
       " 'learning',\n",
       " 'is',\n",
       " 'the',\n",
       " 'key',\n",
       " 'to',\n",
       " 'achieving',\n",
       " 'success',\n",
       " '.',\n",
       " 'so',\n",
       " ',',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'be',\n",
       " 'afraid',\n",
       " 'to',\n",
       " 'take',\n",
       " 'risks',\n",
       " ',',\n",
       " 'dream',\n",
       " 'big',\n",
       " ',',\n",
       " 'and',\n",
       " 'make',\n",
       " 'your',\n",
       " 'mark',\n",
       " 'on',\n",
       " 'this',\n",
       " 'exciting',\n",
       " 'adventure',\n",
       " 'called',\n",
       " 'life',\n",
       " '.']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ph = word_tokenize(ph)\n",
    "ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6ec98357",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['world',\n",
       " 'full',\n",
       " 'challenges',\n",
       " ',',\n",
       " 'often',\n",
       " 'encounter',\n",
       " '900',\n",
       " 'unexpected',\n",
       " 'twists',\n",
       " 'turns',\n",
       " 'journey',\n",
       " '.',\n",
       " 'life',\n",
       " \"'s\",\n",
       " 'path',\n",
       " 'always',\n",
       " 'smooth',\n",
       " ',',\n",
       " \"'s\",\n",
       " 'essential',\n",
       " 'navigate',\n",
       " 'highs',\n",
       " 'lows',\n",
       " 'resilience',\n",
       " 'determination',\n",
       " '!',\n",
       " 'embracing',\n",
       " 'obstacle',\n",
       " 'opportunity',\n",
       " 'growth',\n",
       " 'learning',\n",
       " 'key',\n",
       " 'achieving',\n",
       " 'success',\n",
       " '.',\n",
       " ',',\n",
       " \"n't\",\n",
       " 'afraid',\n",
       " 'take',\n",
       " 'risks',\n",
       " ',',\n",
       " 'dream',\n",
       " 'big',\n",
       " ',',\n",
       " 'make',\n",
       " 'mark',\n",
       " 'exciting',\n",
       " 'adventure',\n",
       " 'called',\n",
       " 'life',\n",
       " '.']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ph = [i for i in ph if i not in stopwords.words('english')]\n",
    "ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "31247e7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world full challeng , often encount 900 unexpect twist turn journey . life 's path alway smooth , 's essenti navig high low resili determin ! embrac obstacl opportun growth learn key achiev success . , n't afraid take risk , dream big , make mark excit adventur call life .\n"
     ]
    }
   ],
   "source": [
    "ptt = PorterStemmer()\n",
    "ph_pt = [ptt.stem(i) for i in ph]\n",
    "ph_pt = \" \".join(ph_pt)\n",
    "print(ph_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "56f0bc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world full challenge , often encounter 900 unexpected twist turn journey . life 's path always smooth , 's essential navigate high low resilience determination ! embracing obstacle opportunity growth learning key achieving success . , n't afraid take risk , dream big , make mark exciting adventure called life .\n"
     ]
    }
   ],
   "source": [
    "w_lem = WordNetLemmatizer()\n",
    "w_lem = [w_lem.lemmatize(i) for i in ph]\n",
    "w_lem = \" \".join(w_lem)\n",
    "print(w_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17da8e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
