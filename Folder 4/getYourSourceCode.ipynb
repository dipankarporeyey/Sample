{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b843a552",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "NumPy\n",
      "=====\n",
      "\n",
      "Provides\n",
      "  1. An array object of arbitrary homogeneous items\n",
      "  2. Fast mathematical operations over arrays\n",
      "  3. Linear Algebra, Fourier Transforms, Random Number Generation\n",
      "\n",
      "How to use the documentation\n",
      "----------------------------\n",
      "Documentation is available in two forms: docstrings provided\n",
      "with the code, and a loose standing reference guide, available from\n",
      "`the NumPy homepage <https://numpy.org>`_.\n",
      "\n",
      "We recommend exploring the docstrings using\n",
      "`IPython <https://ipython.org>`_, an advanced Python shell with\n",
      "TAB-completion and introspection capabilities.  See below for further\n",
      "instructions.\n",
      "\n",
      "The docstring examples assume that `numpy` has been imported as ``np``::\n",
      "\n",
      "  >>> import numpy as np\n",
      "\n",
      "Code snippets are indicated by three greater-than signs::\n",
      "\n",
      "  >>> x = 42\n",
      "  >>> x = x + 1\n",
      "\n",
      "Use the built-in ``help`` function to view a function's docstring::\n",
      "\n",
      "  >>> help(np.sort)\n",
      "  ... # doctest: +SKIP\n",
      "\n",
      "For some objects, ``np.info(obj)`` may provide additional help.  This is\n",
      "particularly true if you see the line \"Help on ufunc object:\" at the top\n",
      "of the help() page.  Ufuncs are implemented in C, not Python, for speed.\n",
      "The native Python help() does not know how to view their help, but our\n",
      "np.info() function does.\n",
      "\n",
      "To search for documents containing a keyword, do::\n",
      "\n",
      "  >>> np.lookfor('keyword')\n",
      "  ... # doctest: +SKIP\n",
      "\n",
      "General-purpose documents like a glossary and help on the basic concepts\n",
      "of numpy are available under the ``doc`` sub-module::\n",
      "\n",
      "  >>> from numpy import doc\n",
      "  >>> help(doc)\n",
      "  ... # doctest: +SKIP\n",
      "\n",
      "Available subpackages\n",
      "---------------------\n",
      "lib\n",
      "    Basic functions used by several sub-packages.\n",
      "random\n",
      "    Core Random Tools\n",
      "linalg\n",
      "    Core Linear Algebra Tools\n",
      "fft\n",
      "    Core FFT routines\n",
      "polynomial\n",
      "    Polynomial tools\n",
      "testing\n",
      "    NumPy testing tools\n",
      "distutils\n",
      "    Enhancements to distutils with support for\n",
      "    Fortran compilers support and more.\n",
      "\n",
      "Utilities\n",
      "---------\n",
      "test\n",
      "    Run numpy unittests\n",
      "show_config\n",
      "    Show numpy build configuration\n",
      "dual\n",
      "    Overwrite certain functions with high-performance SciPy tools.\n",
      "    Note: `numpy.dual` is deprecated.  Use the functions from NumPy or Scipy\n",
      "    directly instead of importing them from `numpy.dual`.\n",
      "matlib\n",
      "    Make everything matrices.\n",
      "__version__\n",
      "    NumPy version string\n",
      "\n",
      "Viewing documentation using IPython\n",
      "-----------------------------------\n",
      "\n",
      "Start IPython and import `numpy` usually under the alias ``np``: `import\n",
      "numpy as np`.  Then, directly past or use the ``%cpaste`` magic to paste\n",
      "examples into the shell.  To see which functions are available in `numpy`,\n",
      "type ``np.<TAB>`` (where ``<TAB>`` refers to the TAB key), or use\n",
      "``np.*cos*?<ENTER>`` (where ``<ENTER>`` refers to the ENTER key) to narrow\n",
      "down the list.  To view the docstring for a function, use\n",
      "``np.cos?<ENTER>`` (to view the docstring) and ``np.cos??<ENTER>`` (to view\n",
      "the source code).\n",
      "\n",
      "Copies vs. in-place operation\n",
      "-----------------------------\n",
      "Most of the functions in `numpy` return a copy of the array argument\n",
      "(e.g., `np.sort`).  In-place versions of these functions are often\n",
      "available as array methods, i.e. ``x = np.array([1,2,3]); x.sort()``.\n",
      "Exceptions to this rule are documented.\n",
      "\n",
      "\"\"\"\n",
      "import sys\n",
      "import warnings\n",
      "\n",
      "from ._globals import (\n",
      "    ModuleDeprecationWarning, VisibleDeprecationWarning,\n",
      "    _NoValue, _CopyMode\n",
      ")\n",
      "\n",
      "# We first need to detect if we're being called as part of the numpy setup\n",
      "# procedure itself in a reliable manner.\n",
      "try:\n",
      "    __NUMPY_SETUP__\n",
      "except NameError:\n",
      "    __NUMPY_SETUP__ = False\n",
      "\n",
      "if __NUMPY_SETUP__:\n",
      "    sys.stderr.write('Running from numpy source directory.\\n')\n",
      "else:\n",
      "    try:\n",
      "        from numpy.__config__ import show as show_config\n",
      "    except ImportError as e:\n",
      "        msg = \"\"\"Error importing numpy: you should not try to import numpy from\n",
      "        its source directory; please exit the numpy source tree, and relaunch\n",
      "        your python interpreter from there.\"\"\"\n",
      "        raise ImportError(msg) from e\n",
      "\n",
      "    __all__ = ['ModuleDeprecationWarning',\n",
      "               'VisibleDeprecationWarning']\n",
      "\n",
      "    # mapping of {name: (value, deprecation_msg)}\n",
      "    __deprecated_attrs__ = {}\n",
      "\n",
      "    # Allow distributors to run custom init code\n",
      "    from . import _distributor_init\n",
      "\n",
      "    from . import core\n",
      "    from .core import *\n",
      "    from . import compat\n",
      "    from . import lib\n",
      "    # NOTE: to be revisited following future namespace cleanup.\n",
      "    # See gh-14454 and gh-15672 for discussion.\n",
      "    from .lib import *\n",
      "\n",
      "    from . import linalg\n",
      "    from . import fft\n",
      "    from . import polynomial\n",
      "    from . import random\n",
      "    from . import ctypeslib\n",
      "    from . import ma\n",
      "    from . import matrixlib as _mat\n",
      "    from .matrixlib import *\n",
      "\n",
      "    # Deprecations introduced in NumPy 1.20.0, 2020-06-06\n",
      "    import builtins as _builtins\n",
      "\n",
      "    _msg = (\n",
      "        \"module 'numpy' has no attribute '{n}'.\\n\"\n",
      "        \"`np.{n}` was a deprecated alias for the builtin `{n}`. \"\n",
      "        \"To avoid this error in existing code, use `{n}` by itself. \"\n",
      "        \"Doing this will not modify any behavior and is safe. {extended_msg}\\n\"\n",
      "        \"The aliases was originally deprecated in NumPy 1.20; for more \"\n",
      "        \"details and guidance see the original release note at:\\n\"\n",
      "        \"    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\")\n",
      "\n",
      "    _specific_msg = (\n",
      "        \"If you specifically wanted the numpy scalar type, use `np.{}` here.\")\n",
      "\n",
      "    _int_extended_msg = (\n",
      "        \"When replacing `np.{}`, you may wish to use e.g. `np.int64` \"\n",
      "        \"or `np.int32` to specify the precision. If you wish to review \"\n",
      "        \"your current use, check the release note link for \"\n",
      "        \"additional information.\")\n",
      "\n",
      "    _type_info = [\n",
      "        (\"object\", \"\"),  # The NumPy scalar only exists by name.\n",
      "        (\"bool\", _specific_msg.format(\"bool_\")),\n",
      "        (\"float\", _specific_msg.format(\"float64\")),\n",
      "        (\"complex\", _specific_msg.format(\"complex128\")),\n",
      "        (\"str\", _specific_msg.format(\"str_\")),\n",
      "        (\"int\", _int_extended_msg.format(\"int\"))]\n",
      "\n",
      "    __former_attrs__ = {\n",
      "         n: _msg.format(n=n, extended_msg=extended_msg)\n",
      "         for n, extended_msg in _type_info\n",
      "     }\n",
      "\n",
      "    # Future warning introduced in NumPy 1.24.0, 2022-11-17\n",
      "    _msg = (\n",
      "        \"`np.{n}` is a deprecated alias for `{an}`.  (Deprecated NumPy 1.24)\")\n",
      "\n",
      "    # Some of these are awkward (since `np.str` may be preferable in the long\n",
      "    # term), but overall the names ending in 0 seem undesireable\n",
      "    _type_info = [\n",
      "        (\"bool8\", bool_, \"np.bool_\"),\n",
      "        (\"int0\", intp, \"np.intp\"),\n",
      "        (\"uint0\", uintp, \"np.uintp\"),\n",
      "        (\"str0\", str_, \"np.str_\"),\n",
      "        (\"bytes0\", bytes_, \"np.bytes_\"),\n",
      "        (\"void0\", void, \"np.void\"),\n",
      "        (\"object0\", object_,\n",
      "            \"`np.object0` is a deprecated alias for `np.object_`. \"\n",
      "            \"`object` can be used instead.  (Deprecated NumPy 1.24)\")]\n",
      "\n",
      "    # Some of these could be defined right away, but most were aliases to\n",
      "    # the Python objects and only removed in NumPy 1.24.  Defining them should\n",
      "    # probably wait for NumPy 1.26 or 2.0.\n",
      "    # When defined, these should possibly not be added to `__all__` to avoid\n",
      "    # import with `from numpy import *`.\n",
      "    __future_scalars__ = {\"bool\", \"long\", \"ulong\", \"str\", \"bytes\", \"object\"}\n",
      "\n",
      "    __deprecated_attrs__.update({\n",
      "        n: (alias, _msg.format(n=n, an=an)) for n, alias, an in _type_info})\n",
      "\n",
      "    del _msg, _type_info\n",
      "\n",
      "    from .core import round, abs, max, min\n",
      "    # now that numpy modules are imported, can initialize limits\n",
      "    core.getlimits._register_known_types()\n",
      "\n",
      "    __all__.extend(['__version__', 'show_config'])\n",
      "    __all__.extend(core.__all__)\n",
      "    __all__.extend(_mat.__all__)\n",
      "    __all__.extend(lib.__all__)\n",
      "    __all__.extend(['linalg', 'fft', 'random', 'ctypeslib', 'ma'])\n",
      "\n",
      "    # Remove one of the two occurrences of `issubdtype`, which is exposed as\n",
      "    # both `numpy.core.issubdtype` and `numpy.lib.issubdtype`.\n",
      "    __all__.remove('issubdtype')\n",
      "\n",
      "    # These are exported by np.core, but are replaced by the builtins below\n",
      "    # remove them to ensure that we don't end up with `np.long == np.int_`,\n",
      "    # which would be a breaking change.\n",
      "    del long, unicode\n",
      "    __all__.remove('long')\n",
      "    __all__.remove('unicode')\n",
      "\n",
      "    # Remove things that are in the numpy.lib but not in the numpy namespace\n",
      "    # Note that there is a test (numpy/tests/test_public_api.py:test_numpy_namespace)\n",
      "    # that prevents adding more things to the main namespace by accident.\n",
      "    # The list below will grow until the `from .lib import *` fixme above is\n",
      "    # taken care of\n",
      "    __all__.remove('Arrayterator')\n",
      "    del Arrayterator\n",
      "\n",
      "    # These names were removed in NumPy 1.20.  For at least one release,\n",
      "    # attempts to access these names in the numpy namespace will trigger\n",
      "    # a warning, and calling the function will raise an exception.\n",
      "    _financial_names = ['fv', 'ipmt', 'irr', 'mirr', 'nper', 'npv', 'pmt',\n",
      "                        'ppmt', 'pv', 'rate']\n",
      "    __expired_functions__ = {\n",
      "        name: (f'In accordance with NEP 32, the function {name} was removed '\n",
      "               'from NumPy version 1.20.  A replacement for this function '\n",
      "               'is available in the numpy_financial library: '\n",
      "               'https://pypi.org/project/numpy-financial')\n",
      "        for name in _financial_names}\n",
      "\n",
      "    # Filter out Cython harmless warnings\n",
      "    warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
      "    warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
      "    warnings.filterwarnings(\"ignore\", message=\"numpy.ndarray size changed\")\n",
      "\n",
      "    # oldnumeric and numarray were removed in 1.9. In case some packages import\n",
      "    # but do not use them, we define them here for backward compatibility.\n",
      "    oldnumeric = 'removed'\n",
      "    numarray = 'removed'\n",
      "\n",
      "    def __getattr__(attr):\n",
      "        # Warn for expired attributes, and return a dummy function\n",
      "        # that always raises an exception.\n",
      "        import warnings\n",
      "        try:\n",
      "            msg = __expired_functions__[attr]\n",
      "        except KeyError:\n",
      "            pass\n",
      "        else:\n",
      "            warnings.warn(msg, DeprecationWarning, stacklevel=2)\n",
      "\n",
      "            def _expired(*args, **kwds):\n",
      "                raise RuntimeError(msg)\n",
      "\n",
      "            return _expired\n",
      "\n",
      "        # Emit warnings for deprecated attributes\n",
      "        try:\n",
      "            val, msg = __deprecated_attrs__[attr]\n",
      "        except KeyError:\n",
      "            pass\n",
      "        else:\n",
      "            warnings.warn(msg, DeprecationWarning, stacklevel=2)\n",
      "            return val\n",
      "\n",
      "        if attr in __future_scalars__:\n",
      "            # And future warnings for those that will change, but also give\n",
      "            # the AttributeError\n",
      "            warnings.warn(\n",
      "                f\"In the future `np.{attr}` will be defined as the \"\n",
      "                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n",
      "\n",
      "        if attr in __former_attrs__:\n",
      "            raise AttributeError(__former_attrs__[attr])\n",
      "\n",
      "        # Importing Tester requires importing all of UnitTest which is not a\n",
      "        # cheap import Since it is mainly used in test suits, we lazy import it\n",
      "        # here to save on the order of 10 ms of import time for most users\n",
      "        #\n",
      "        # The previous way Tester was imported also had a side effect of adding\n",
      "        # the full `numpy.testing` namespace\n",
      "        if attr == 'testing':\n",
      "            import numpy.testing as testing\n",
      "            return testing\n",
      "        elif attr == 'Tester':\n",
      "            from .testing import Tester\n",
      "            return Tester\n",
      "\n",
      "        raise AttributeError(\"module {!r} has no attribute \"\n",
      "                             \"{!r}\".format(__name__, attr))\n",
      "\n",
      "    def __dir__():\n",
      "        public_symbols = globals().keys() | {'Tester', 'testing'}\n",
      "        public_symbols -= {\n",
      "            \"core\", \"matrixlib\",\n",
      "        }\n",
      "        return list(public_symbols)\n",
      "\n",
      "    # Pytest testing\n",
      "    from numpy._pytesttester import PytestTester\n",
      "    test = PytestTester(__name__)\n",
      "    del PytestTester\n",
      "\n",
      "    def _sanity_check():\n",
      "        \"\"\"\n",
      "        Quick sanity checks for common bugs caused by environment.\n",
      "        There are some cases e.g. with wrong BLAS ABI that cause wrong\n",
      "        results under specific runtime conditions that are not necessarily\n",
      "        achieved during test suite runs, and it is useful to catch those early.\n",
      "\n",
      "        See https://github.com/numpy/numpy/issues/8577 and other\n",
      "        similar bug reports.\n",
      "\n",
      "        \"\"\"\n",
      "        try:\n",
      "            x = ones(2, dtype=float32)\n",
      "            if not abs(x.dot(x) - float32(2.0)) < 1e-5:\n",
      "                raise AssertionError()\n",
      "        except AssertionError:\n",
      "            msg = (\"The current Numpy installation ({!r}) fails to \"\n",
      "                   \"pass simple sanity checks. This can be caused for example \"\n",
      "                   \"by incorrect BLAS library being linked in, or by mixing \"\n",
      "                   \"package managers (pip, conda, apt, ...). Search closed \"\n",
      "                   \"numpy issues for similar problems.\")\n",
      "            raise RuntimeError(msg.format(__file__)) from None\n",
      "\n",
      "    _sanity_check()\n",
      "    del _sanity_check\n",
      "\n",
      "    def _mac_os_check():\n",
      "        \"\"\"\n",
      "        Quick Sanity check for Mac OS look for accelerate build bugs.\n",
      "        Testing numpy polyfit calls init_dgelsd(LAPACK)\n",
      "        \"\"\"\n",
      "        try:\n",
      "            c = array([3., 2., 1.])\n",
      "            x = linspace(0, 2, 5)\n",
      "            y = polyval(c, x)\n",
      "            _ = polyfit(x, y, 2, cov=True)\n",
      "        except ValueError:\n",
      "            pass\n",
      "\n",
      "    if sys.platform == \"darwin\":\n",
      "        with warnings.catch_warnings(record=True) as w:\n",
      "            _mac_os_check()\n",
      "            # Throw runtime error, if the test failed Check for warning and error_message\n",
      "            error_message = \"\"\n",
      "            if len(w) > 0:\n",
      "                error_message = \"{}: {}\".format(w[-1].category.__name__, str(w[-1].message))\n",
      "                msg = (\n",
      "                    \"Polyfit sanity test emitted a warning, most likely due \"\n",
      "                    \"to using a buggy Accelerate backend.\"\n",
      "                    \"\\nIf you compiled yourself, more information is available at:\"\n",
      "                    \"\\nhttps://numpy.org/doc/stable/user/building.html#accelerated-blas-lapack-libraries\"\n",
      "                    \"\\nOtherwise report this to the vendor \"\n",
      "                    \"that provided NumPy.\\n{}\\n\".format(error_message))\n",
      "                raise RuntimeError(msg)\n",
      "    del _mac_os_check\n",
      "\n",
      "    # We usually use madvise hugepages support, but on some old kernels it\n",
      "    # is slow and thus better avoided.\n",
      "    # Specifically kernel version 4.6 had a bug fix which probably fixed this:\n",
      "    # https://github.com/torvalds/linux/commit/7cf91a98e607c2f935dbcc177d70011e95b8faff\n",
      "    import os\n",
      "    use_hugepage = os.environ.get(\"NUMPY_MADVISE_HUGEPAGE\", None)\n",
      "    if sys.platform == \"linux\" and use_hugepage is None:\n",
      "        # If there is an issue with parsing the kernel version,\n",
      "        # set use_hugepages to 0. Usage of LooseVersion will handle\n",
      "        # the kernel version parsing better, but avoided since it\n",
      "        # will increase the import time. See: #16679 for related discussion.\n",
      "        try:\n",
      "            use_hugepage = 1\n",
      "            kernel_version = os.uname().release.split(\".\")[:2]\n",
      "            kernel_version = tuple(int(v) for v in kernel_version)\n",
      "            if kernel_version < (4, 6):\n",
      "                use_hugepage = 0\n",
      "        except ValueError:\n",
      "            use_hugepages = 0\n",
      "    elif use_hugepage is None:\n",
      "        # This is not Linux, so it should not matter, just enable anyway\n",
      "        use_hugepage = 1\n",
      "    else:\n",
      "        use_hugepage = int(use_hugepage)\n",
      "\n",
      "    # Note that this will currently only make a difference on Linux\n",
      "    core.multiarray._set_madvise_hugepage(use_hugepage)\n",
      "\n",
      "    # Give a warning if NumPy is reloaded or imported on a sub-interpreter\n",
      "    # We do this from python, since the C-module may not be reloaded and\n",
      "    # it is tidier organized.\n",
      "    core.multiarray._multiarray_umath._reload_guard()\n",
      "\n",
      "    core._set_promotion_state(os.environ.get(\"NPY_PROMOTION_STATE\", \"legacy\"))\n",
      "\n",
      "    # Tell PyInstaller where to find hook-numpy.py\n",
      "    def _pyinstaller_hooks_dir():\n",
      "        from pathlib import Path\n",
      "        return [str(Path(__file__).with_name(\"_pyinstaller\").resolve())]\n",
      "\n",
      "    # Remove symbols imported for internal use\n",
      "    del os\n",
      "\n",
      "    import mkl\n",
      "    __mkl_version__ = \"{MajorVersion}.{MinorVersion}.{UpdateVersion}\".format(**mkl.get_version())\n",
      "\n",
      "\n",
      "# get the version using versioneer\n",
      "from .version import __version__, git_revision as __git_version__\n",
      "\n",
      "# Remove symbols imported for internal use\n",
      "del sys, warnings\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import inspect\n",
    "src = inspect.getsource(np)\n",
    "print(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6f9c8db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from __future__ import annotations\n",
      "\n",
      "__docformat__ = \"restructuredtext\"\n",
      "\n",
      "# Let users know if they're missing any of our hard dependencies\n",
      "_hard_dependencies = (\"numpy\", \"pytz\", \"dateutil\")\n",
      "_missing_dependencies = []\n",
      "\n",
      "for _dependency in _hard_dependencies:\n",
      "    try:\n",
      "        __import__(_dependency)\n",
      "    except ImportError as _e:\n",
      "        _missing_dependencies.append(f\"{_dependency}: {_e}\")\n",
      "\n",
      "if _missing_dependencies:\n",
      "    raise ImportError(\n",
      "        \"Unable to import required dependencies:\\n\" + \"\\n\".join(_missing_dependencies)\n",
      "    )\n",
      "del _hard_dependencies, _dependency, _missing_dependencies\n",
      "\n",
      "# numpy compat\n",
      "from pandas.compat import is_numpy_dev as _is_numpy_dev  # pyright: ignore # noqa:F401\n",
      "\n",
      "try:\n",
      "    from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib\n",
      "except ImportError as _err:  # pragma: no cover\n",
      "    _module = _err.name\n",
      "    raise ImportError(\n",
      "        f\"C extension: {_module} not built. If you want to import \"\n",
      "        \"pandas from the source directory, you may need to run \"\n",
      "        \"'python setup.py build_ext --force' to build the C extensions first.\"\n",
      "    ) from _err\n",
      "else:\n",
      "    del _tslib, _lib, _hashtable\n",
      "\n",
      "from pandas._config import (\n",
      "    get_option,\n",
      "    set_option,\n",
      "    reset_option,\n",
      "    describe_option,\n",
      "    option_context,\n",
      "    options,\n",
      ")\n",
      "\n",
      "# let init-time option registration happen\n",
      "import pandas.core.config_init  # pyright: ignore # noqa:F401\n",
      "\n",
      "from pandas.core.api import (\n",
      "    # dtype\n",
      "    ArrowDtype,\n",
      "    Int8Dtype,\n",
      "    Int16Dtype,\n",
      "    Int32Dtype,\n",
      "    Int64Dtype,\n",
      "    UInt8Dtype,\n",
      "    UInt16Dtype,\n",
      "    UInt32Dtype,\n",
      "    UInt64Dtype,\n",
      "    Float32Dtype,\n",
      "    Float64Dtype,\n",
      "    CategoricalDtype,\n",
      "    PeriodDtype,\n",
      "    IntervalDtype,\n",
      "    DatetimeTZDtype,\n",
      "    StringDtype,\n",
      "    BooleanDtype,\n",
      "    # missing\n",
      "    NA,\n",
      "    isna,\n",
      "    isnull,\n",
      "    notna,\n",
      "    notnull,\n",
      "    # indexes\n",
      "    Index,\n",
      "    CategoricalIndex,\n",
      "    RangeIndex,\n",
      "    MultiIndex,\n",
      "    IntervalIndex,\n",
      "    TimedeltaIndex,\n",
      "    DatetimeIndex,\n",
      "    PeriodIndex,\n",
      "    IndexSlice,\n",
      "    # tseries\n",
      "    NaT,\n",
      "    Period,\n",
      "    period_range,\n",
      "    Timedelta,\n",
      "    timedelta_range,\n",
      "    Timestamp,\n",
      "    date_range,\n",
      "    bdate_range,\n",
      "    Interval,\n",
      "    interval_range,\n",
      "    DateOffset,\n",
      "    # conversion\n",
      "    to_numeric,\n",
      "    to_datetime,\n",
      "    to_timedelta,\n",
      "    # misc\n",
      "    Flags,\n",
      "    Grouper,\n",
      "    factorize,\n",
      "    unique,\n",
      "    value_counts,\n",
      "    NamedAgg,\n",
      "    array,\n",
      "    Categorical,\n",
      "    set_eng_float_format,\n",
      "    Series,\n",
      "    DataFrame,\n",
      ")\n",
      "\n",
      "from pandas.core.arrays.sparse import SparseDtype\n",
      "\n",
      "from pandas.tseries.api import infer_freq\n",
      "from pandas.tseries import offsets\n",
      "\n",
      "from pandas.core.computation.api import eval\n",
      "\n",
      "from pandas.core.reshape.api import (\n",
      "    concat,\n",
      "    lreshape,\n",
      "    melt,\n",
      "    wide_to_long,\n",
      "    merge,\n",
      "    merge_asof,\n",
      "    merge_ordered,\n",
      "    crosstab,\n",
      "    pivot,\n",
      "    pivot_table,\n",
      "    get_dummies,\n",
      "    from_dummies,\n",
      "    cut,\n",
      "    qcut,\n",
      ")\n",
      "\n",
      "from pandas import api, arrays, errors, io, plotting, tseries\n",
      "from pandas import testing  # noqa:PDF015\n",
      "from pandas.util._print_versions import show_versions\n",
      "\n",
      "from pandas.io.api import (\n",
      "    # excel\n",
      "    ExcelFile,\n",
      "    ExcelWriter,\n",
      "    read_excel,\n",
      "    # parsers\n",
      "    read_csv,\n",
      "    read_fwf,\n",
      "    read_table,\n",
      "    # pickle\n",
      "    read_pickle,\n",
      "    to_pickle,\n",
      "    # pytables\n",
      "    HDFStore,\n",
      "    read_hdf,\n",
      "    # sql\n",
      "    read_sql,\n",
      "    read_sql_query,\n",
      "    read_sql_table,\n",
      "    # misc\n",
      "    read_clipboard,\n",
      "    read_parquet,\n",
      "    read_orc,\n",
      "    read_feather,\n",
      "    read_gbq,\n",
      "    read_html,\n",
      "    read_xml,\n",
      "    read_json,\n",
      "    read_stata,\n",
      "    read_sas,\n",
      "    read_spss,\n",
      ")\n",
      "\n",
      "from pandas.io.json import _json_normalize as json_normalize\n",
      "\n",
      "from pandas.util._tester import test\n",
      "\n",
      "# use the closest tagged version if possible\n",
      "from pandas._version import get_versions\n",
      "\n",
      "v = get_versions()\n",
      "__version__ = v.get(\"closest-tag\", v[\"version\"])\n",
      "__git_version__ = v.get(\"full-revisionid\")\n",
      "del get_versions, v\n",
      "\n",
      "# GH 27101\n",
      "__deprecated_num_index_names = [\"Float64Index\", \"Int64Index\", \"UInt64Index\"]\n",
      "\n",
      "\n",
      "def __dir__() -> list[str]:\n",
      "    # GH43028\n",
      "    # Int64Index etc. are deprecated, but we still want them to be available in the dir.\n",
      "    # Remove in Pandas 2.0, when we remove Int64Index etc. from the code base.\n",
      "    return list(globals().keys()) + __deprecated_num_index_names\n",
      "\n",
      "\n",
      "def __getattr__(name):\n",
      "    import warnings\n",
      "\n",
      "    if name in __deprecated_num_index_names:\n",
      "        warnings.warn(\n",
      "            f\"pandas.{name} is deprecated \"\n",
      "            \"and will be removed from pandas in a future version. \"\n",
      "            \"Use pandas.Index with the appropriate dtype instead.\",\n",
      "            FutureWarning,\n",
      "            stacklevel=2,\n",
      "        )\n",
      "        from pandas.core.api import Float64Index, Int64Index, UInt64Index\n",
      "\n",
      "        return {\n",
      "            \"Float64Index\": Float64Index,\n",
      "            \"Int64Index\": Int64Index,\n",
      "            \"UInt64Index\": UInt64Index,\n",
      "        }[name]\n",
      "    elif name == \"datetime\":\n",
      "        warnings.warn(\n",
      "            \"The pandas.datetime class is deprecated \"\n",
      "            \"and will be removed from pandas in a future version. \"\n",
      "            \"Import from datetime module instead.\",\n",
      "            FutureWarning,\n",
      "            stacklevel=2,\n",
      "        )\n",
      "\n",
      "        from datetime import datetime as dt\n",
      "\n",
      "        return dt\n",
      "\n",
      "    elif name == \"np\":\n",
      "\n",
      "        warnings.warn(\n",
      "            \"The pandas.np module is deprecated \"\n",
      "            \"and will be removed from pandas in a future version. \"\n",
      "            \"Import numpy directly instead.\",\n",
      "            FutureWarning,\n",
      "            stacklevel=2,\n",
      "        )\n",
      "        import numpy as np\n",
      "\n",
      "        return np\n",
      "\n",
      "    elif name in {\"SparseSeries\", \"SparseDataFrame\"}:\n",
      "        warnings.warn(\n",
      "            f\"The {name} class is removed from pandas. Accessing it from \"\n",
      "            \"the top-level namespace will also be removed in the next version.\",\n",
      "            FutureWarning,\n",
      "            stacklevel=2,\n",
      "        )\n",
      "\n",
      "        return type(name, (), {})\n",
      "\n",
      "    elif name == \"SparseArray\":\n",
      "\n",
      "        warnings.warn(\n",
      "            \"The pandas.SparseArray class is deprecated \"\n",
      "            \"and will be removed from pandas in a future version. \"\n",
      "            \"Use pandas.arrays.SparseArray instead.\",\n",
      "            FutureWarning,\n",
      "            stacklevel=2,\n",
      "        )\n",
      "        from pandas.core.arrays.sparse import SparseArray as _SparseArray\n",
      "\n",
      "        return _SparseArray\n",
      "\n",
      "    raise AttributeError(f\"module 'pandas' has no attribute '{name}'\")\n",
      "\n",
      "\n",
      "# module level doc-string\n",
      "__doc__ = \"\"\"\n",
      "pandas - a powerful data analysis and manipulation library for Python\n",
      "=====================================================================\n",
      "\n",
      "**pandas** is a Python package providing fast, flexible, and expressive data\n",
      "structures designed to make working with \"relational\" or \"labeled\" data both\n",
      "easy and intuitive. It aims to be the fundamental high-level building block for\n",
      "doing practical, **real world** data analysis in Python. Additionally, it has\n",
      "the broader goal of becoming **the most powerful and flexible open source data\n",
      "analysis / manipulation tool available in any language**. It is already well on\n",
      "its way toward this goal.\n",
      "\n",
      "Main Features\n",
      "-------------\n",
      "Here are just a few of the things that pandas does well:\n",
      "\n",
      "  - Easy handling of missing data in floating point as well as non-floating\n",
      "    point data.\n",
      "  - Size mutability: columns can be inserted and deleted from DataFrame and\n",
      "    higher dimensional objects\n",
      "  - Automatic and explicit data alignment: objects can be explicitly aligned\n",
      "    to a set of labels, or the user can simply ignore the labels and let\n",
      "    `Series`, `DataFrame`, etc. automatically align the data for you in\n",
      "    computations.\n",
      "  - Powerful, flexible group by functionality to perform split-apply-combine\n",
      "    operations on data sets, for both aggregating and transforming data.\n",
      "  - Make it easy to convert ragged, differently-indexed data in other Python\n",
      "    and NumPy data structures into DataFrame objects.\n",
      "  - Intelligent label-based slicing, fancy indexing, and subsetting of large\n",
      "    data sets.\n",
      "  - Intuitive merging and joining data sets.\n",
      "  - Flexible reshaping and pivoting of data sets.\n",
      "  - Hierarchical labeling of axes (possible to have multiple labels per tick).\n",
      "  - Robust IO tools for loading data from flat files (CSV and delimited),\n",
      "    Excel files, databases, and saving/loading data from the ultrafast HDF5\n",
      "    format.\n",
      "  - Time series-specific functionality: date range generation and frequency\n",
      "    conversion, moving window statistics, date shifting and lagging.\n",
      "\"\"\"\n",
      "\n",
      "# Use __all__ to let type checkers know what is part of the public API.\n",
      "# Pandas is not (yet) a py.typed library: the public API is determined\n",
      "# based on the documentation.\n",
      "__all__ = [\n",
      "    \"ArrowDtype\",\n",
      "    \"BooleanDtype\",\n",
      "    \"Categorical\",\n",
      "    \"CategoricalDtype\",\n",
      "    \"CategoricalIndex\",\n",
      "    \"DataFrame\",\n",
      "    \"DateOffset\",\n",
      "    \"DatetimeIndex\",\n",
      "    \"DatetimeTZDtype\",\n",
      "    \"ExcelFile\",\n",
      "    \"ExcelWriter\",\n",
      "    \"Flags\",\n",
      "    \"Float32Dtype\",\n",
      "    \"Float64Dtype\",\n",
      "    \"Grouper\",\n",
      "    \"HDFStore\",\n",
      "    \"Index\",\n",
      "    \"IndexSlice\",\n",
      "    \"Int16Dtype\",\n",
      "    \"Int32Dtype\",\n",
      "    \"Int64Dtype\",\n",
      "    \"Int8Dtype\",\n",
      "    \"Interval\",\n",
      "    \"IntervalDtype\",\n",
      "    \"IntervalIndex\",\n",
      "    \"MultiIndex\",\n",
      "    \"NA\",\n",
      "    \"NaT\",\n",
      "    \"NamedAgg\",\n",
      "    \"Period\",\n",
      "    \"PeriodDtype\",\n",
      "    \"PeriodIndex\",\n",
      "    \"RangeIndex\",\n",
      "    \"Series\",\n",
      "    \"SparseDtype\",\n",
      "    \"StringDtype\",\n",
      "    \"Timedelta\",\n",
      "    \"TimedeltaIndex\",\n",
      "    \"Timestamp\",\n",
      "    \"UInt16Dtype\",\n",
      "    \"UInt32Dtype\",\n",
      "    \"UInt64Dtype\",\n",
      "    \"UInt8Dtype\",\n",
      "    \"api\",\n",
      "    \"array\",\n",
      "    \"arrays\",\n",
      "    \"bdate_range\",\n",
      "    \"concat\",\n",
      "    \"crosstab\",\n",
      "    \"cut\",\n",
      "    \"date_range\",\n",
      "    \"describe_option\",\n",
      "    \"errors\",\n",
      "    \"eval\",\n",
      "    \"factorize\",\n",
      "    \"get_dummies\",\n",
      "    \"from_dummies\",\n",
      "    \"get_option\",\n",
      "    \"infer_freq\",\n",
      "    \"interval_range\",\n",
      "    \"io\",\n",
      "    \"isna\",\n",
      "    \"isnull\",\n",
      "    \"json_normalize\",\n",
      "    \"lreshape\",\n",
      "    \"melt\",\n",
      "    \"merge\",\n",
      "    \"merge_asof\",\n",
      "    \"merge_ordered\",\n",
      "    \"notna\",\n",
      "    \"notnull\",\n",
      "    \"offsets\",\n",
      "    \"option_context\",\n",
      "    \"options\",\n",
      "    \"period_range\",\n",
      "    \"pivot\",\n",
      "    \"pivot_table\",\n",
      "    \"plotting\",\n",
      "    \"qcut\",\n",
      "    \"read_clipboard\",\n",
      "    \"read_csv\",\n",
      "    \"read_excel\",\n",
      "    \"read_feather\",\n",
      "    \"read_fwf\",\n",
      "    \"read_gbq\",\n",
      "    \"read_hdf\",\n",
      "    \"read_html\",\n",
      "    \"read_json\",\n",
      "    \"read_orc\",\n",
      "    \"read_parquet\",\n",
      "    \"read_pickle\",\n",
      "    \"read_sas\",\n",
      "    \"read_spss\",\n",
      "    \"read_sql\",\n",
      "    \"read_sql_query\",\n",
      "    \"read_sql_table\",\n",
      "    \"read_stata\",\n",
      "    \"read_table\",\n",
      "    \"read_xml\",\n",
      "    \"reset_option\",\n",
      "    \"set_eng_float_format\",\n",
      "    \"set_option\",\n",
      "    \"show_versions\",\n",
      "    \"test\",\n",
      "    \"testing\",\n",
      "    \"timedelta_range\",\n",
      "    \"to_datetime\",\n",
      "    \"to_numeric\",\n",
      "    \"to_pickle\",\n",
      "    \"to_timedelta\",\n",
      "    \"tseries\",\n",
      "    \"unique\",\n",
      "    \"value_counts\",\n",
      "    \"wide_to_long\",\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import inspect\n",
    "src = inspect.getsource(pd)\n",
    "print(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb8cee30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# -*- coding: utf-8 -*-\n",
      "\"\"\"\n",
      "PandasAI is a wrapper around a LLM to make dataframes conversational\n",
      "\n",
      "This module includes the implementation of basis  PandasAI class with methods to run\n",
      "the LLMs models on Pandas dataframes. Following LLMs are implemented so far.\n",
      "\n",
      "Example:\n",
      "\n",
      "    This module is the Entry point of the `pandasai` package. Following is an example\n",
      "    of how to use this Class.\n",
      "\n",
      "    ```python\n",
      "    import pandas as pd\n",
      "    from pandasai import PandasAI\n",
      "\n",
      "    # Sample DataFrame\n",
      "    df = pd.DataFrame({\n",
      "        \"country\": [\"United States\", \"United Kingdom\", \"France\", \"Germany\", \"Italy\",\n",
      "        \"Spain\", \"Canada\", \"Australia\", \"Japan\", \"China\"],\n",
      "        \"gdp\": [19294482071552, 2891615567872, 2411255037952, 3435817336832,\n",
      "        1745433788416, 1181205135360, 1607402389504, 1490967855104, 4380756541440,\n",
      "        14631844184064],\n",
      "        \"happiness_index\": [6.94, 7.16, 6.66, 7.07, 6.38, 6.4, 7.23, 7.22, 5.87, 5.12]\n",
      "    })\n",
      "\n",
      "    # Instantiate a LLM\n",
      "    from pandasai.llm.openai import OpenAI\n",
      "    llm = OpenAI(api_token=\"YOUR_API_TOKEN\")\n",
      "\n",
      "    pandas_ai = PandasAI(llm)\n",
      "    pandas_ai(df, prompt='Which are the 5 happiest countries?')\n",
      "\n",
      "    ```\n",
      "\"\"\"\n",
      "\n",
      "from typing import List, Optional, Union, Dict, Type\n",
      "import importlib.metadata\n",
      "\n",
      "import pandas as pd\n",
      "from .smart_dataframe import SmartDataframe\n",
      "from .smart_datalake import SmartDatalake\n",
      "from .prompts.base import Prompt\n",
      "from .callbacks.base import BaseCallback\n",
      "from .helpers.df_config import Config\n",
      "from .helpers.cache import Cache\n",
      "\n",
      "__version__ = importlib.metadata.version(__package__ or __name__)\n",
      "\n",
      "\n",
      "class PandasAI:\n",
      "    \"\"\"\n",
      "    PandasAI is a wrapper around a LLM to make dataframes conversational.\n",
      "\n",
      "\n",
      "    This is an entry point of `pandasai` object. This class consists of methods\n",
      "    to interface the LLMs with Pandas     dataframes. A pandas dataframe metadata i.e.\n",
      "    df.head() and prompt is passed on to chosen LLMs API end point to generate a Python\n",
      "    code to answer the questions asked. The resultant python code is run on actual data\n",
      "    and answer is converted into a conversational form.\n",
      "\n",
      "    Note:\n",
      "        Do not include the `self` parameter in the ``Args`` section.\n",
      "    Args:\n",
      "        _llm (obj): LLMs option to be used for API access\n",
      "        _verbose (bool, optional): To show the intermediate outputs e.g. python code\n",
      "        generated and execution step on the prompt. Default to False\n",
      "        _enforce_privacy (bool, optional): Do not display the data on prompt in case of\n",
      "        Sensitive data. Default to False\n",
      "        _max_retries (int, optional): max no. of tries to generate code on failure.\n",
      "        Default to 3\n",
      "        _in_notebook (bool, optional): Whether to run code in notebook. Default to False\n",
      "        _original_instructions (dict, optional): The dict of instruction to run. Default\n",
      "        to None\n",
      "        _cache (Cache, optional): Cache object to store the results. Default to None\n",
      "        _enable_cache (bool, optional): Whether to enable cache. Default to True\n",
      "        _logger (logging.Logger, optional): Logger object to log the messages. Default\n",
      "        to None\n",
      "        _logs (List[dict], optional): List of logs to be stored. Default to []\n",
      "        _prompt_id (str, optional): Unique ID to differentiate calls. Default to None\n",
      "        _middlewares (List[Middleware], optional): List of middlewares to run. Default\n",
      "        to [ChartsMiddleware()]\n",
      "        _additional_dependencies (List[dict], optional): List of additional dependencies\n",
      "        to be added. Default to []\n",
      "        _custom_whitelisted_dependencies (List[str], optional): List of custom\n",
      "        whitelisted dependencies. Default to []\n",
      "        last_code_generated (str, optional): Pass last Code if generated. Default to\n",
      "        None\n",
      "        last_code_executed (str, optional): Pass the last execution / run. Default to\n",
      "        None\n",
      "        code_output (str, optional): The code output if any. Default to None\n",
      "        last_error (str, optional): Error of running code last time. Default to None\n",
      "        prompt_id (str, optional): Unique ID to differentiate calls. Default to None\n",
      "\n",
      "\n",
      "    Returns (str): Response to a Question related to Data\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    _dl: SmartDatalake = None\n",
      "    _config: Config\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        llm=None,\n",
      "        conversational=False,\n",
      "        verbose=False,\n",
      "        enforce_privacy=False,\n",
      "        save_charts=False,\n",
      "        save_charts_path=\"\",\n",
      "        enable_cache=True,\n",
      "        middlewares=[],\n",
      "        custom_whitelisted_dependencies=[],\n",
      "        enable_logging=True,\n",
      "        non_default_prompts: Optional[Dict[str, Type[Prompt]]] = None,\n",
      "        callback: Optional[BaseCallback] = None,\n",
      "    ):\n",
      "        \"\"\"\n",
      "        __init__ method of the Class PandasAI\n",
      "\n",
      "        Args:\n",
      "            llm (object): LLMs option to be used for API access. Default is None\n",
      "            conversational (bool): Whether to return answer in conversational form.\n",
      "            Default to False\n",
      "            verbose (bool): To show the intermediate outputs e.g. python code\n",
      "            generated and execution step on the prompt.  Default to False\n",
      "            enforce_privacy (bool): Execute the codes with Privacy Mode ON.\n",
      "            Default to False\n",
      "            save_charts (bool): Save the charts generated in the notebook.\n",
      "            Default to False\n",
      "            enable_cache (bool): Enable the cache to store the results.\n",
      "            Default to True\n",
      "            middlewares (list): List of middlewares to be used. Default to None\n",
      "            custom_whitelisted_dependencies (list): List of custom dependencies to\n",
      "            be used. Default to None\n",
      "            enable_logging (bool): Enable the logging. Default to True\n",
      "            non_default_prompts (dict): Mapping from keys to replacement prompt classes.\n",
      "            Used to override specific types of prompts. Defaults to None.\n",
      "        \"\"\"\n",
      "\n",
      "        # configure the logging\n",
      "        # noinspection PyArgumentList\n",
      "        # https://stackoverflow.com/questions/61226587/pycharm-does-not-recognize-logging-basicconfig-handlers-argument\n",
      "\n",
      "        self._config = Config(\n",
      "            conversational=conversational,\n",
      "            verbose=verbose,\n",
      "            enforce_privacy=enforce_privacy,\n",
      "            save_charts=save_charts,\n",
      "            save_charts_path=save_charts_path,\n",
      "            enable_cache=enable_cache,\n",
      "            middlewares=middlewares,\n",
      "            custom_whitelisted_dependencies=custom_whitelisted_dependencies,\n",
      "            enable_logging=enable_logging,\n",
      "            non_default_prompts=non_default_prompts,\n",
      "            llm=llm,\n",
      "            callback=callback,\n",
      "        )\n",
      "\n",
      "    def run(\n",
      "        self,\n",
      "        data_frame: Union[pd.DataFrame, List[pd.DataFrame]],\n",
      "        prompt: str,\n",
      "        show_code: bool = False,\n",
      "        anonymize_df: bool = True,\n",
      "        use_error_correction_framework: bool = True,\n",
      "    ) -> Union[str, pd.DataFrame]:\n",
      "        \"\"\"\n",
      "        Run the PandasAI to make Dataframes Conversational.\n",
      "\n",
      "        Args:\n",
      "            data_frame (Union[pd.DataFrame, List[pd.DataFrame]]): A pandas Dataframe\n",
      "            prompt (str): A prompt to query about the Dataframe\n",
      "            show_code (bool): To show the intermediate python code generated on the\n",
      "            prompt. Default to False\n",
      "            anonymize_df (bool): Running the code with Sensitive Data. Default to True\n",
      "            use_error_correction_framework (bool): Turn on Error Correction mechanism.\n",
      "            Default to True\n",
      "\n",
      "        Returns (str): Answer to the Input Questions about the DataFrame\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        new_config = self._config.dict()\n",
      "        new_config[\"show_code\"] = show_code\n",
      "        new_config[\"anonymize_df\"] = anonymize_df\n",
      "        new_config[\"use_error_correction_framework\"] = use_error_correction_framework\n",
      "\n",
      "        config = Config(**new_config).dict()\n",
      "\n",
      "        if not isinstance(data_frame, list):\n",
      "            data_frame = [data_frame]\n",
      "\n",
      "        self._dl = SmartDatalake(data_frame, config)\n",
      "        return self._dl.chat(prompt)\n",
      "\n",
      "    def __call__(\n",
      "        self,\n",
      "        data_frame: Union[pd.DataFrame, List[pd.DataFrame]],\n",
      "        prompt: str,\n",
      "        show_code: bool = False,\n",
      "        anonymize_df: bool = True,\n",
      "        use_error_correction_framework: bool = True,\n",
      "    ) -> Union[str, pd.DataFrame]:\n",
      "        \"\"\"\n",
      "        __call__ method of PandasAI class. It calls the `run` method.\n",
      "\n",
      "        Args:\n",
      "            data_frame:\n",
      "            prompt:\n",
      "            show_code:\n",
      "            anonymize_df:\n",
      "            use_error_correction_framework:\n",
      "\n",
      "        Returns (str): Answer to the Input Questions about the DataFrame.\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        return self.run(\n",
      "            data_frame,\n",
      "            prompt,\n",
      "            show_code,\n",
      "            anonymize_df,\n",
      "            use_error_correction_framework,\n",
      "        )\n",
      "\n",
      "    @property\n",
      "    def logs(self) -> List[dict[str, str]]:\n",
      "        \"\"\"Return the logs\"\"\"\n",
      "        if self._dl is None:\n",
      "            return []\n",
      "        return self._dl.logs\n",
      "\n",
      "    @property\n",
      "    def last_prompt_id(self) -> str:\n",
      "        \"\"\"Return the id of the last prompt that was run.\"\"\"\n",
      "        if self._dl is None:\n",
      "            return None\n",
      "        return self._dl.last_prompt_id\n",
      "\n",
      "    @property\n",
      "    def last_prompt(self) -> str:\n",
      "        \"\"\"Return the last prompt that was executed.\"\"\"\n",
      "        if self._dl is None:\n",
      "            return None\n",
      "        return self._dl.last_prompt\n",
      "\n",
      "\n",
      "def clear_cache(filename: str = None):\n",
      "    \"\"\"Clear the cache\"\"\"\n",
      "    cache = Cache(filename or \"cache\")\n",
      "    cache.clear()\n",
      "\n",
      "\n",
      "__all__ = [\"PandasAI\", \"SmartDataframe\", \"SmartDatalake\", \"clear_cache\"]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandasai as pai\n",
    "import inspect\n",
    "src = inspect.getsource(pai)\n",
    "print(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252006e3",
   "metadata": {},
   "source": [
    "                                                    -:END:-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
